---
title: "Move Mirror"
demo: https://experiments.withgoogle.com/collection/ai/move-mirror/view
code: https://github.com/tensorflow/tfjs-models/tree/master/posenet
link: https://medium.com/tensorflow/move-mirror-an-ai-experiment-with-pose-estimation-in-the-browser-using-tensorflow-js-2f7b769f9b23
date: "2018-07-19"
path: "/inspire/move-mirror"
thumbnail: "./img/move-mirror.jpg"
author: "Jane Friedhoff & Irene Alvarado"
authorAvatar: https://pbs.twimg.com/profile_images/688851090691891200/pYSFP5sz_400x400.jpg
authorLink: https://twitter.com/ire_alva
shortDescription: "An AI Experiment which matches your pose with a catalogue of 80,000 photos while you move"
tags:
  - TensorFlow.js
  - PoseNet
layout: "inspire"
---

<figure class="video_container">
  <video controls="true" autoplay loop allowfullscreen="true" poster="./img/move-mirror.jpg">
    <source src="https://www.youtube.com/watch?v=JvzkFJW6LIU" type="video/mp4">
  </video>
</figure>

Move Mirror lets you explore pictures in a fun new way. You turn on your
webcam and move around, and the computer pulls up pictures of poses that
match yours in realtime.

The image database is made of more than 80,000 pictures of people dancing,
doing karate, cooking, walking, skiing etc.